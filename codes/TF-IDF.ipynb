{"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from google.colab import drive\n","\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# read train data\n","with open('/content/drive/MyDrive/LUN_data/raw_data/fulltrain.csv', 'r') as file:\n","    train = pd.read_csv(file, names=['class', 'text'])\n","\n","# read test data\n","with open('/content/drive/MyDrive/LUN_data/raw_data/balancedtest.csv', 'r') as file:\n","    test = pd.read_csv(file, names=['class', 'text'])\n","\n","# read stop words\n","with open('/content/drive/MyDrive/LUN_data/raw_data/stopwords_en.txt', 'r') as file:\n","    stop_words = file.read().splitlines()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mzFD6sS-sa_1","executionInfo":{"status":"ok","timestamp":1710684841973,"user_tz":-480,"elapsed":5019,"user":{"displayName":"cyan eude","userId":"02152818965630538055"}},"outputId":"0050af0b-6c06-47b8-dc6a-c47dee060b22"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["## Feature Engineering"],"metadata":{"id":"9EL4SlEMyj0r"}},{"cell_type":"code","source":["def remove_inconsistent(df):\n","    grouped = df.groupby('text')['class']\n","    consistent_duplicates = grouped.transform(lambda x: x.nunique() == 1)\n","    inconsistent_duplicates = df[~consistent_duplicates].copy()\n","    df.drop(inconsistent_duplicates.index, inplace=True)\n","    return df\n","\n","def remove_all_duplicates(df):\n","    return df.drop_duplicates(subset='text', keep='first')\n","\n","# Remove inconsistent entries\n","train = remove_inconsistent(train)\n","\n","# Remove all remaining duplicates\n","train = remove_all_duplicates(train)"],"metadata":{"id":"TgM0E3GZWIPq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","import string\n","import nltk\n","\n","def preprocess_text(text):\n","    \"\"\"\n","    Preprocesses text data:\n","      * Lowercasing\n","      * Removing square brackets and content\n","      * Removing links\n","      * Removing punctuation\n","      * Removing numbers\n","      * Removing stop words\n","      * Stemming (optional)\n","\n","    Args:\n","       text: Input text string\n","\n","    Returns:\n","       Cleaned text string\n","    \"\"\"\n","    text = text.lower()\n","    text = re.sub('\\[.*?\\]', '', text)\n","    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n","    text = re.sub('<.*?>+', '', text)\n","    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n","    text = re.sub('\\n', '', text)\n","    text = re.sub('\\w*\\d\\w*', '', text)\n","\n","    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n","    tokens = tokenizer.tokenize(text)\n","\n","    words = [w for w in tokens if w not in stop_words]\n","\n","    return ' '.join(words)"],"metadata":{"id":"AQn6kNYnWqwb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train['text'] = train['text'].apply(preprocess_text)\n","test['text'] = test['text'].apply(preprocess_text)"],"metadata":{"id":"9u1_fwqUW4ME"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import LabelEncoder\n","\n","X_train = train['text']\n","X_test = test['text']\n","\n","# Create TF-IDF vectorizer\n","tfidf_vectorizer = TfidfVectorizer(max_features=20000)\n","\n","X_train = tfidf_vectorizer.fit_transform(X_train)\n","X_train = X_train.toarray()\n","\n","X_test = tfidf_vectorizer.transform(X_test)\n","X_test = X_test.toarray()\n","\n","# # Convert labels to one-hot form\n","# y_train = pd.get_dummies(df['class'])"],"metadata":{"id":"UexLq5jeXhWq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train_vectors = pd.DataFrame(X_train, columns=tfidf_vectorizer.get_feature_names_out())\n","# train_vectors.to_csv('fulltrain_tfidf_vectors.csv', index=False)\n","\n","# test_vectors = pd.DataFrame(X_test, columns=tfidf_vectorizer.get_feature_names_out())\n","# test_vectors.to_csv('test_tfidf_vectors.csv', index=False)"],"metadata":{"id":"VPNPUMutYg_C"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"colab":{"provenance":[],"machine_shape":"hm"}},"nbformat":4,"nbformat_minor":0}